{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be29a63",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "   \n",
    "# **üìä Data Science Jobs Analysis üíº** \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9989c84d",
   "metadata": {},
   "source": [
    "# <u>**Problem Statement**:\n",
    "<img src=\"image.jpg\" alt=\"Description\" style=\"width: 70%; height: auto;\" />\n",
    "\n",
    "**The objective of this project is to analyze job listings data scraped from Naukri.com to gain insights into the data science job market üìà. The dataset includes various features such as job titles, companies, required experience, locations, salary ranges üíº, and key skills demanded by employers in the data science field. The primary goal is to understand the key trends üîç in job requirements, company ratings, and skill sets to help aspiring data scientists üßë‚Äçüíª make informed decisions about career growth, skill development, and job opportunities. This project will involve comprehensive data cleaning üßπ, exploratory data analysis üìä, and visualization üñºÔ∏è to uncover valuable insights into the current job market landscape.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f99505",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "   \n",
    "# **SPRINT 1 - Web Scraping** \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c691c4f",
   "metadata": {},
   "source": [
    "## **Description**\n",
    "\n",
    "\n",
    "In Sprint 1, we focused on web scraping job listings from Naukri.com to gather valuable insights into the data science job market. We utilized **Selenium**, a powerful web automation tool, to create a script that interacts with web elements dynamically and extracts relevant job data.\n",
    "\n",
    "The coding procedure involves the following key steps:\n",
    "\n",
    "1. **Setup**: We initialized the Selenium WebDriver (e.g., ChromeDriver) to launch the web browser and navigate to the Naukri.com job listings pages.\n",
    "\n",
    "2. **Looping Through Pages**: A loop was implemented to iterate through multiple job listing pages, enabling us to scrape data across different listings efficiently.\n",
    "\n",
    "3. **Locating Elements**: Using various XPath selectors, we identified and extracted key data points:\n",
    "   - **Job Title and Company**: Extracted using the XPath `'.//div[@class=\"row1\"]'`.\n",
    "   - **Job Posting Date**: Retrieved using `'.//span[@class=\"job-post-day\"]'`.\n",
    "   - **Job Details**: Located through `'.//div[@class=\"job-details\"]'`, which includes experience requirements and location.\n",
    "\n",
    "4. **Storing Data**: Each extracted element was stored in corresponding lists (e.g., `titles`, `companies`, `days`, etc.) for further analysis.\n",
    "\n",
    "This foundational data collection process will support our analysis in later sprints, enabling us to uncover valuable insights into the data science job market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393c826a-82c3-4722-816a-185a85daa6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3cea4632-8d71-4f58-b5df-7ace0233cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists to store the extracted data\n",
    "title=[]\n",
    "company=[]\n",
    "ratings=[]\n",
    "reviews=[]\n",
    "years=[]\n",
    "location=[]\n",
    "days=[]\n",
    "salary=[]\n",
    "skills=[]\n",
    "como=[]\n",
    "key_skills=[]\n",
    "\n",
    "#initializing chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "#iterating through the pages\n",
    "for j in range(1,111):\n",
    "    url = f\"https://www.naukri.com/data-science-jobs-{j}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    for i in driver.find_elements(By.XPATH , './/div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]'):\n",
    "        \n",
    "        #Extracting job title\n",
    "        t = i.find_element(By.XPATH , './/div[@class=\" row1\"]')\n",
    "        if t.text is None:\n",
    "            title.append(np.nan)\n",
    "        else:\n",
    "            title.append(t.text)\n",
    "            \n",
    "        #Extracting the name of the company\n",
    "        c = i.find_element(By.XPATH , './/div[@class=\" row2\"]')\n",
    "        if re.findall(\"(^\\w+.*)\\\\n\\d\\.\",c.text):\n",
    "            company.append(''.join(re.findall(\"(^\\w+.*)\\\\n\\d\\.\",c.text)))\n",
    "        else:\n",
    "            company.append(np.nan)\n",
    "            \n",
    "        #Extracting the ratings of the company \n",
    "        if re.findall(\"\\d\\.\\d\",c.text):\n",
    "            ratings.append(re.findall(\"\\d\\.\\d\",c.text)[0])\n",
    "        else:\n",
    "            ratings.append(np.nan)\n",
    "            \n",
    "        #Extracting the reviews\n",
    "        if re.findall(\"\\d+(?= Reviews)\",c.text):\n",
    "            reviews.append(re.findall(\"\\d+(?= Reviews)\",c.text)[0])\n",
    "        else:\n",
    "            reviews.append(np.nan)\n",
    "            \n",
    "        #Extracting years of experience\n",
    "        y = i.find_element(By.XPATH , './/div[@class=\"job-details \"]')\n",
    "        if re.findall(\"\\d\\-\\d.\",y.text):\n",
    "            years.append(re.findall(\"\\d\\-\\d.\",y.text)[0])\n",
    "        else:\n",
    "            years.append(np.nan)\n",
    "            \n",
    "        #Extracting the location of the job.\n",
    "        l = i.find_element(By.XPATH , './/div[@class=\"job-details \"]')\n",
    "        if re.findall('\\\\n\\w.*\\\\n(.*)',l.text):\n",
    "            location.append(''.join(re.findall('\\\\n\\w.*\\\\n(.*)',l.text)))\n",
    "        else:\n",
    "            location.append(np.nan)\n",
    "            \n",
    "        #Extracting the number of days ago, the job was posted\n",
    "        d = i.find_element(By.XPATH , './/span[@class=\"job-post-day \"]')\n",
    "        if re.findall(\"\\d\",y.text):\n",
    "            days.append(re.findall(\"\\d\",y.text)[0])\n",
    "        elif \"Just Now\" in y.text:\n",
    "            years.append(1)\n",
    "            continue\n",
    "        else:\n",
    "            days.append(np.nan)\n",
    "            \n",
    "        #Extracting the salary if disclosed\n",
    "        s = i.find_element(By.XPATH , './/div[@class=\"job-details \"]')\n",
    "        if re.findall(\"\\\\n(.*)\\\\n\",s.text):\n",
    "            salary.append(''.join(re.findall(\"\\\\n(.*)\\\\n\",s.text)))\n",
    "        else:\n",
    "            salary.append(np.nan)\n",
    "            \n",
    "        #Extracting the skills and then extracting key skills from the skills\n",
    "        try:\n",
    "            sk = i.find_element(By.XPATH, './/ul[@class=\"tags-gt \"]')\n",
    "            skills.append(sk.text) \n",
    "        except NoSuchElementException:\n",
    "            skills.append(np.nan)  \n",
    "        try:\n",
    "            sk1=i.find_element(By.XPATH, './/ul[@class=\"tags-gt \"]')\n",
    "            skill=re.findall(r\"\"\"(?i)(data analytics|machine learning|python|matplotlib|seaborn|pandas|excel|sql|numpy|\n",
    "                  natural language processing|nlp|deep learning|dl|ml|visualization|java|C\\+\\+|\n",
    "                  image processing|sas|bet|statistical modelling|data science|data analysis|data mining|\n",
    "                  data analyst|statistical analysis|data engineer|statistics|big data|predictive modelling|\n",
    "                  data security|time series analysis|data collection|data engineering|gen ai|cloud services|\n",
    "                  aws|automation|azure|nosql|mysql|llm|tensorflow|pyspark|ai|artificial intelligence|\n",
    "                  sap|data processing|power bi|powerbi|business analysis|data management|neural networks)\"\"\", sk.text)\n",
    "            \n",
    "            key_skills.append(','.join(skill))\n",
    "        except NoSuchElementException:\n",
    "            key_skills.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data frame\n",
    "d0=pd.DataFrame({\"title\":title,\n",
    "               \"company\":company,\n",
    "                \"ratings\":ratings,\n",
    "                \"reviews\":reviews,\n",
    "                \"years\":years,\n",
    "                \"location\":location,\n",
    "                \"days\":days,\n",
    "                \"salary\":salary,\n",
    "                \"skills\":skills,\n",
    "                \"key_skills\":key_skills})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to csv\n",
    "d0.to_csv('Nakuri.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9c9be8aa-3221-4434-b50d-6a670e37a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the csv file\n",
    "df=pd.read_csv('Nakuri.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ccc12d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "df.drop('skills',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fca71d",
   "metadata": {},
   "source": [
    "##  <u>**Column Description**</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a724a",
   "metadata": {},
   "source": [
    "- **title**: The job title or position being advertised (e.g., Data Scientist, Data Analyst, etc.).\n",
    "- **company**: The name of the company posting the job listing.\n",
    "- **ratings**: The rating of the company (if available) as given by employees or users.\n",
    "- **reviews**: The number of reviews left for the company.\n",
    "- **years**: The required range of years of experience for the job (e.g., 2-5 years).\n",
    "- **location**: The geographical location of the job (e.g., city or region).\n",
    "- **days**: The number of days ago the job was posted.\n",
    "- **salary**: The salary offered for the job (if provided in the listing).\n",
    "- **key_skills**: Specific technical skills extracted from the job description (e.g., Python, SQL, Machine Learning, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8191316c-2069-4a16-b47b-6be317ed006e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>years</th>\n",
       "      <th>location</th>\n",
       "      <th>days</th>\n",
       "      <th>salary</th>\n",
       "      <th>key_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R&amp;D- Data Science and Analytics Lead</td>\n",
       "      <td>Pepsi Foods</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>2-5</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Machine learning,big data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Specialist- Data Science &amp; Analytics</td>\n",
       "      <td>Carrier</td>\n",
       "      <td>3.8</td>\n",
       "      <td>419.0</td>\n",
       "      <td>2-5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>ai,data science,Neural networks,Artificial Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Analytics Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>3-5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>data mining,machine learning,excel,python,data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science &amp; Analytics Engagement Lead</td>\n",
       "      <td>CANPACK</td>\n",
       "      <td>4.3</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0-15</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>sql,data science,data mining,power bi,machine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc Manager, Data Science Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>excel,python,data mining</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title      company  ratings  reviews   \n",
       "0      R&D- Data Science and Analytics Lead  Pepsi Foods      4.1   2308.0  \\\n",
       "1      Specialist- Data Science & Analytics      Carrier      3.8    419.0   \n",
       "2            Data Science Analytics Analyst    Accenture      4.0  49777.0   \n",
       "3  Data Science & Analytics Engagement Lead      CANPACK      4.3    236.0   \n",
       "4     Assoc Manager, Data Science Analytics          NaN      NaN      NaN   \n",
       "\n",
       "  years   location  days         salary   \n",
       "0  2-5   Hyderabad   2.0  Not disclosed  \\\n",
       "1  2-5   Bengaluru   2.0  Not disclosed   \n",
       "2  3-5   Bengaluru   3.0  Not disclosed   \n",
       "3  0-15       Pune   1.0  Not disclosed   \n",
       "4  3-6   Bengaluru   3.0  Not disclosed   \n",
       "\n",
       "                                          key_skills  \n",
       "0                          Machine learning,big data  \n",
       "1  ai,data science,Neural networks,Artificial Int...  \n",
       "2  data mining,machine learning,excel,python,data...  \n",
       "3  sql,data science,data mining,power bi,machine ...  \n",
       "4                           excel,python,data mining  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "13f8f51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2172 entries, 0 to 2171\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   title       2171 non-null   object \n",
      " 1   company     1711 non-null   object \n",
      " 2   ratings     1711 non-null   float64\n",
      " 3   reviews     1711 non-null   float64\n",
      " 4   years       2168 non-null   object \n",
      " 5   location    2171 non-null   object \n",
      " 6   days        2171 non-null   float64\n",
      " 7   salary      2171 non-null   object \n",
      " 8   key_skills  2139 non-null   object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 152.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca80b1",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "   \n",
    "# **SPRINT 2 - Data Wrangling** \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a77dbc4",
   "metadata": {},
   "source": [
    "### Sprint 2: Data Wrangling\n",
    "\n",
    "In Sprint 2, we focused on data wrangling to prepare the scraped job listings dataset for analysis. This phase is crucial as it transforms raw data into a clean, structured format, enabling us to derive meaningful insights.\n",
    "\n",
    "The data wrangling procedure involves several key steps:\n",
    "\n",
    "1. **Data Cleaning**: We began by addressing missing values, duplicates, and inconsistencies within the dataset. This included removing any job postings that lacked essential information such as job titles or company names.\n",
    "\n",
    "2. **Data Type Conversion**: We ensured that each column was of the appropriate data type. For example, salary ranges were converted from strings to numerical values, and dates were formatted for easier manipulation.\n",
    "\n",
    "3. **Feature Engineering**: New features were created to enhance the dataset. For instance, we extracted the minimum and maximum salary from the salary range column and categorized job titles into broader roles (e.g., Data Analyst, Data Scientist).\n",
    "\n",
    "4. **Text Normalization**: To facilitate analysis, we standardized text fields by converting them to lowercase and removing unnecessary whitespace or special characters, ensuring consistency across the dataset.\n",
    "\n",
    "5. **Data Transformation**: Finally, we transformed the dataset into a tidy format, organizing it for easy analysis. This included pivoting tables and encoding categorical variables as needed.\n",
    "\n",
    "By the end of Sprint 2, the dataset was well-prepared, laying a solid foundation for the exploratory data analysis in the subsequent sprint. This comprehensive data wrangling process is essential for ensuring the reliability and accuracy of our findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce35670",
   "metadata": {},
   "source": [
    "### **Changes made to the data**\n",
    "\n",
    "- Fixing the salary column .\n",
    "  1) Filling not disclosed with nan.\n",
    "  2) converting thousand to lakhs\n",
    "  3) creating 2 separate columns for staring and ending range of the salary.\n",
    "  4) Converting data type of minmum and maximum salary.\n",
    "  5) Dropping the salary column.\n",
    "- Fixing year column\n",
    "  1) Creating two columns (min_year, max_year) from the column year.\n",
    "  2) Converting the data type of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469c63d",
   "metadata": {},
   "source": [
    "####  <u>**Fixing salary column**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049ec80",
   "metadata": {},
   "source": [
    "Filling not disclised values with null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed98befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['salary'] = df['salary'].replace('Not disclosed', np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4986651a",
   "metadata": {},
   "source": [
    "Removing all the text from the salary solumn so that it willl be easy to extract the minimum and maximu  salary from the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0c91fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'] = df['salary'].str.replace(' Lacs PA','').str.replace(' Cr and above PA','').str.replace('5 Cr PA','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0130458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'] = df['salary'].str.replace(' PA','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e34970c",
   "metadata": {},
   "source": [
    "Converting thousands to lakhs:<br>\n",
    "Since there are only two values in thousands, we are fixing it manually, if not we can do it with loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "412abe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'] = df['salary'].str.replace('50,000','0.5').str.replace('80,000','0.8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b6d8c",
   "metadata": {},
   "source": [
    "Extracting minimum salary and maximum salary from the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5a4ed5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return str(''.join(re.findall('(\\d+.*)\\-',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "820c449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_salary']=df['salary'].apply(lambda x: find_min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f51d09ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>min_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10-20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1-3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.5-5.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>18-25</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5-10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2.75-5</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>22.5-25</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>35-40</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>4-8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>10-15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       salary min_salary\n",
       "33      10-20         10\n",
       "46        1-3          1\n",
       "47    4.5-5.5        4.5\n",
       "51      18-25         18\n",
       "70       5-10          5\n",
       "...       ...        ...\n",
       "2072   2.75-5       2.75\n",
       "2098  22.5-25       22.5\n",
       "2114    35-40         35\n",
       "2115      4-8          4\n",
       "2116    10-15         10\n",
       "\n",
       "[178 rows x 2 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['salary'].notna()][['salary','min_salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "10fa3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return str(''.join(re.findall('\\-(.*)',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2676d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['max_salary'] = df['salary'].apply(lambda x: find_max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7bd9f126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '20', '3', '5.5', '25', '10', '22', '22.5', '9', '24', '14',\n",
       "       '15', '45', '30', '40', '2.', '17', '18', '60', '3.75', '4', '21',\n",
       "       '5', '35', '4.5', '8', '4.25', '13', '7', '65', '12', '16', '34',\n",
       "       '17.5', '', '27.5', '32.5', '42.5', '6', '4.75', '1', '11', '9.5',\n",
       "       '2.5', '70'], dtype=object)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['max_salary'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "aa9500ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10-20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1-3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.5-5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>18-25</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5-10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2.75-5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>22.5-25</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>35-40</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>4-8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>10-15</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       salary min_salary max_salary\n",
       "33      10-20         10         20\n",
       "46        1-3          1          3\n",
       "47    4.5-5.5        4.5        5.5\n",
       "51      18-25         18         25\n",
       "70       5-10          5         10\n",
       "...       ...        ...        ...\n",
       "2072   2.75-5       2.75          5\n",
       "2098  22.5-25       22.5         25\n",
       "2114    35-40         35         40\n",
       "2115      4-8          4          8\n",
       "2116    10-15         10         15\n",
       "\n",
       "[178 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['salary'].notna()][['salary','min_salary','max_salary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d68ca",
   "metadata": {},
   "source": [
    "Converting the datatype of minimum salry are the maximum salry to float from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9863bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_salary'] = df['min_salary'].replace('',np.nan)\n",
    "df['max_salary'] = df['min_salary'].replace('',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "74159d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '10', '1', '4.5', '18', '5', '12', '7', '14', '7.5', '30',\n",
       "       '20', '25', '8', '15', '35', '2.5', '2', '9', '11', '4', '1.5',\n",
       "       '3.5', '3', '50', '6', '0', '6.5', '9.5', '13', '27.5', '0.5',\n",
       "       '3.25', '22.5', '0.8', '5.5', '2.75', '37.5', '1.75', '60'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['min_salary'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8a56a241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2172 entries, 0 to 2171\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   min_salary  176 non-null    object\n",
      " 1   max_salary  176 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df[['min_salary','max_salary']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1f4c79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['min_salary','max_salary']] = df[['min_salary','max_salary']].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4841cfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2172 entries, 0 to 2171\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   min_salary  176 non-null    float64\n",
      " 1   max_salary  176 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 34.1 KB\n"
     ]
    }
   ],
   "source": [
    "df[['min_salary','max_salary']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc3618",
   "metadata": {},
   "source": [
    "Dropping salary column as it is not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9072f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('salary',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dfbbd6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>years</th>\n",
       "      <th>location</th>\n",
       "      <th>days</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R&amp;D- Data Science and Analytics Lead</td>\n",
       "      <td>Pepsi Foods</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>2-5</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Machine learning,big data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Specialist- Data Science &amp; Analytics</td>\n",
       "      <td>Carrier</td>\n",
       "      <td>3.8</td>\n",
       "      <td>419.0</td>\n",
       "      <td>2-5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ai,data science,Neural networks,Artificial Int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Analytics Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>3-5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3.0</td>\n",
       "      <td>data mining,machine learning,excel,python,data...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science &amp; Analytics Engagement Lead</td>\n",
       "      <td>CANPACK</td>\n",
       "      <td>4.3</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0-15</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sql,data science,data mining,power bi,machine ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc Manager, Data Science Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3.0</td>\n",
       "      <td>excel,python,data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title      company  ratings  reviews   \n",
       "0      R&D- Data Science and Analytics Lead  Pepsi Foods      4.1   2308.0  \\\n",
       "1      Specialist- Data Science & Analytics      Carrier      3.8    419.0   \n",
       "2            Data Science Analytics Analyst    Accenture      4.0  49777.0   \n",
       "3  Data Science & Analytics Engagement Lead      CANPACK      4.3    236.0   \n",
       "4     Assoc Manager, Data Science Analytics          NaN      NaN      NaN   \n",
       "\n",
       "  years   location  days                                         key_skills   \n",
       "0  2-5   Hyderabad   2.0                          Machine learning,big data  \\\n",
       "1  2-5   Bengaluru   2.0  ai,data science,Neural networks,Artificial Int...   \n",
       "2  3-5   Bengaluru   3.0  data mining,machine learning,excel,python,data...   \n",
       "3  0-15       Pune   1.0  sql,data science,data mining,power bi,machine ...   \n",
       "4  3-6   Bengaluru   3.0                           excel,python,data mining   \n",
       "\n",
       "   min_salary  max_salary  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ecd6b7",
   "metadata": {},
   "source": [
    "####  <u>**Fixing year column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e5af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
