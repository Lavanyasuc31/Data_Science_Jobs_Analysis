{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be29a63",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "   \n",
    "# **üìä Data Science Jobs Analysis üíº** \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9989c84d",
   "metadata": {},
   "source": [
    "# <u>**Problem Statement**:\n",
    "<img src=\"image.jpg\" alt=\"Description\" style=\"width: 70%; height: auto;\" />\n",
    "\n",
    "**The objective of this project is to analyze job listings data scraped from Naukri.com to gain insights into the data science job market üìà. The dataset includes various features such as job titles, companies, required experience, locations, salary ranges üíº, and key skills demanded by employers in the data science field. The primary goal is to understand the key trends üîç in job requirements, company ratings, and skill sets to help aspiring data scientists üßë‚Äçüíª make informed decisions about career growth, skill development, and job opportunities. This project will involve comprehensive data cleaning üßπ, exploratory data analysis üìä, and visualization üñºÔ∏è to uncover valuable insights into the current job market landscape.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f99505",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "   \n",
    "# **SPRINT 1 - Web Scraping** \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c691c4f",
   "metadata": {},
   "source": [
    "## **Description**\n",
    "\n",
    "\n",
    "In Sprint 1, we focused on web scraping job listings from Naukri.com to gather valuable insights into the data science job market. We utilized **Selenium**, a powerful web automation tool, to create a script that interacts with web elements dynamically and extracts relevant job data.\n",
    "\n",
    "The coding procedure involves the following key steps:\n",
    "\n",
    "1. **Setup**: We initialized the Selenium WebDriver (e.g., ChromeDriver) to launch the web browser and navigate to the Naukri.com job listings pages.\n",
    "\n",
    "2. **Looping Through Pages**: A loop was implemented to iterate through multiple job listing pages, enabling us to scrape data across different listings efficiently.\n",
    "\n",
    "3. **Locating Elements**: Using various XPath selectors, we identified and extracted key data points:\n",
    "   - **Job Title and Company**: Extracted using the XPath `'.//div[@class=\"row1\"]'`.\n",
    "   - **Job Posting Date**: Retrieved using `'.//span[@class=\"job-post-day\"]'`.\n",
    "   - **Job Details**: Located through `'.//div[@class=\"job-details\"]'`, which includes experience requirements and location.\n",
    "\n",
    "4. **Storing Data**: Each extracted element was stored in corresponding lists (e.g., `titles`, `companies`, `days`, etc.) for further analysis.\n",
    "\n",
    "This foundational data collection process will support our analysis in later sprints, enabling us to uncover valuable insights into the data science job market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "393c826a-82c3-4722-816a-185a85daa6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3cea4632-8d71-4f58-b5df-7ace0233cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists to store the extracted data\n",
    "title=[]\n",
    "company=[]\n",
    "ratings=[]\n",
    "reviews=[]\n",
    "years=[]\n",
    "location=[]\n",
    "days=[]\n",
    "salary=[]\n",
    "skills=[]\n",
    "como=[]\n",
    "key_skills=[]\n",
    "\n",
    "#initializing chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "#iterating through the pages\n",
    "for j in range(1,111):\n",
    "    url = f\"https://www.naukri.com/data-science-jobs-{j}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    for i in driver.find_elements(By.XPATH , './/div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]'):\n",
    "        \n",
    "        #Extracting job title\n",
    "        t = i.find_element(By.XPATH , './/div[@class=\" row1\"]')\n",
    "        if t.text is None:\n",
    "            title.append(np.nan)\n",
    "        else:\n",
    "            title.append(t.text)\n",
    "            \n",
    "        #Extracting the name of the company\n",
    "        c = i.find_element(By.XPATH , './/div[@class=\" row2\"]')\n",
    "        if re.findall(\"(^\\w+.*)\\\\n\\d\\.\",c.text):\n",
    "            company.append(''.join(re.findall(\"(^\\w+.*)\\\\n\\d\\.\",c.text)))\n",
    "        else:\n",
    "            company.append(np.nan)\n",
    "            \n",
    "        #Extracting the ratings of the company \n",
    "        if re.findall(\"\\d\\.\\d\",c.text):\n",
    "            ratings.append(re.findall(\"\\d\\.\\d\",c.text)[0])\n",
    "        else:\n",
    "            ratings.append(np.nan)\n",
    "            \n",
    "        #Extracting the reviews\n",
    "        if re.findall(\"\\d+(?= Reviews)\",c.text):\n",
    "            reviews.append(re.findall(\"\\d+(?= Reviews)\",c.text)[0])\n",
    "        else:\n",
    "            reviews.append(np.nan)\n",
    "            \n",
    "        #Extracting years of experience\n",
    "        y = i.find_element(By.XPATH , './/div[@class=\"job-details \"]')\n",
    "        if re.findall(\"\\d\\-\\d.\",y.text):\n",
    "            years.append(re.findall(\"\\d\\-\\d.\",y.text)[0])\n",
    "        else:\n",
    "            years.append(np.nan)\n",
    "            \n",
    "        #Extracting the location of the job.\n",
    "        l = i.find_element(By.XPATH , './/div[@class=\"job-details \"]')\n",
    "        if re.findall('\\\\n\\w.*\\\\n(.*)',l.text):\n",
    "            location.append(''.join(re.findall('\\\\n\\w.*\\\\n(.*)',l.text)))\n",
    "        else:\n",
    "            location.append(np.nan)\n",
    "            \n",
    "        #Extracting the number of days ago, the job was posted\n",
    "        d = i.find_element(By.XPATH , './/span[@class=\"job-post-day \"]')\n",
    "        if re.findall(\"\\d\",y.text):\n",
    "            days.append(re.findall(\"\\d\",y.text)[0])\n",
    "        elif \"Just Now\" in y.text:\n",
    "            years.append(1)\n",
    "            continue\n",
    "        else:\n",
    "            days.append(np.nan)\n",
    "            \n",
    "        #Extracting the salary if disclosed\n",
    "        s = i.find_element(By.XPATH , './/div[@class=\"job-details \"]')\n",
    "        if re.findall(\"\\\\n(.*)\\\\n\",s.text):\n",
    "            salary.append(''.join(re.findall(\"\\\\n(.*)\\\\n\",s.text)))\n",
    "        else:\n",
    "            salary.append(np.nan)\n",
    "            \n",
    "        #Extracting the skills and then extracting key skills from the skills\n",
    "        try:\n",
    "            sk = i.find_element(By.XPATH, './/ul[@class=\"tags-gt \"]')\n",
    "            skills.append(sk.text) \n",
    "        except NoSuchElementException:\n",
    "            skills.append(np.nan)  \n",
    "        try:\n",
    "            sk1=i.find_element(By.XPATH, './/ul[@class=\"tags-gt \"]')\n",
    "            skill=re.findall(r\"\"\"(?i)(data analytics|machine learning|python|matplotlib|seaborn|pandas|excel|sql|numpy|\n",
    "                  natural language processing|nlp|deep learning|dl|ml|visualization|java|C\\+\\+|\n",
    "                  image processing|sas|bet|statistical modelling|data science|data analysis|data mining|\n",
    "                  data analyst|statistical analysis|data engineer|statistics|big data|predictive modelling|\n",
    "                  data security|time series analysis|data collection|data engineering|gen ai|cloud services|\n",
    "                  aws|automation|azure|nosql|mysql|llm|tensorflow|pyspark|ai|artificial intelligence|\n",
    "                  sap|data processing|power bi|powerbi|business analysis|data management|neural networks)\"\"\", sk.text)\n",
    "            \n",
    "            key_skills.append(','.join(skill))\n",
    "        except NoSuchElementException:\n",
    "            key_skills.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data frame\n",
    "d0=pd.DataFrame({\"title\":title,\n",
    "               \"company\":company,\n",
    "                \"ratings\":ratings,\n",
    "                \"reviews\":reviews,\n",
    "                \"years\":years,\n",
    "                \"location\":location,\n",
    "                \"days\":days,\n",
    "                \"salary\":salary,\n",
    "                \"skills\":skills,\n",
    "                \"key_skills\":key_skills})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to csv\n",
    "d0.to_csv('Nakuri.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c9be8aa-3221-4434-b50d-6a670e37a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the csv file\n",
    "df=pd.read_csv('Nakuri.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc12d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "df.drop('skills',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fca71d",
   "metadata": {},
   "source": [
    "##  <u>**Column Description**</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a724a",
   "metadata": {},
   "source": [
    "- **title**: The job title or position being advertised (e.g., Data Scientist, Data Analyst, etc.).\n",
    "- **company**: The name of the company posting the job listing.\n",
    "- **ratings**: The rating of the company (if available) as given by employees or users.\n",
    "- **reviews**: The number of reviews left for the company.\n",
    "- **years**: The required range of years of experience for the job (e.g., 2-5 years).\n",
    "- **location**: The geographical location of the job (e.g., city or region).\n",
    "- **days**: The number of days ago the job was posted.\n",
    "- **salary**: The salary offered for the job (if provided in the listing).\n",
    "- **key_skills**: Specific technical skills extracted from the job description (e.g., Python, SQL, Machine Learning, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8191316c-2069-4a16-b47b-6be317ed006e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>years</th>\n",
       "      <th>location</th>\n",
       "      <th>days</th>\n",
       "      <th>salary</th>\n",
       "      <th>key_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R&amp;D- Data Science and Analytics Lead</td>\n",
       "      <td>Pepsi Foods</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>2-5</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Machine learning,big data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Specialist- Data Science &amp; Analytics</td>\n",
       "      <td>Carrier</td>\n",
       "      <td>3.8</td>\n",
       "      <td>419.0</td>\n",
       "      <td>2-5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>ai,data science,Neural networks,Artificial Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Analytics Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>3-5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>data mining,machine learning,excel,python,data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science &amp; Analytics Engagement Lead</td>\n",
       "      <td>CANPACK</td>\n",
       "      <td>4.3</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0-15</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>sql,data science,data mining,power bi,machine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc Manager, Data Science Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>excel,python,data mining</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title      company  ratings  reviews   \n",
       "0      R&D- Data Science and Analytics Lead  Pepsi Foods      4.1   2308.0  \\\n",
       "1      Specialist- Data Science & Analytics      Carrier      3.8    419.0   \n",
       "2            Data Science Analytics Analyst    Accenture      4.0  49777.0   \n",
       "3  Data Science & Analytics Engagement Lead      CANPACK      4.3    236.0   \n",
       "4     Assoc Manager, Data Science Analytics          NaN      NaN      NaN   \n",
       "\n",
       "  years   location  days         salary   \n",
       "0  2-5   Hyderabad   2.0  Not disclosed  \\\n",
       "1  2-5   Bengaluru   2.0  Not disclosed   \n",
       "2  3-5   Bengaluru   3.0  Not disclosed   \n",
       "3  0-15       Pune   1.0  Not disclosed   \n",
       "4  3-6   Bengaluru   3.0  Not disclosed   \n",
       "\n",
       "                                          key_skills  \n",
       "0                          Machine learning,big data  \n",
       "1  ai,data science,Neural networks,Artificial Int...  \n",
       "2  data mining,machine learning,excel,python,data...  \n",
       "3  sql,data science,data mining,power bi,machine ...  \n",
       "4                           excel,python,data mining  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f8f51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2172 entries, 0 to 2171\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   title       2171 non-null   object \n",
      " 1   company     1711 non-null   object \n",
      " 2   ratings     1711 non-null   float64\n",
      " 3   reviews     1711 non-null   float64\n",
      " 4   years       2168 non-null   object \n",
      " 5   location    2171 non-null   object \n",
      " 6   days        2171 non-null   float64\n",
      " 7   salary      2171 non-null   object \n",
      " 8   key_skills  2139 non-null   object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 152.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca80b1",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "   \n",
    "# **SPRINT 2 - Data Wrangling** \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a77dbc4",
   "metadata": {},
   "source": [
    "### Sprint 2: Data Wrangling\n",
    "\n",
    "In Sprint 2, we focused on data wrangling to prepare the scraped job listings dataset for analysis. This phase is crucial as it transforms raw data into a clean, structured format, enabling us to derive meaningful insights.\n",
    "\n",
    "The data wrangling procedure involves several key steps:\n",
    "\n",
    "1. **Data Cleaning**: We began by addressing missing values, duplicates, and inconsistencies within the dataset. This included removing any job postings that lacked essential information such as job titles or company names.\n",
    "\n",
    "2. **Data Type Conversion**: We ensured that each column was of the appropriate data type. For example, salary ranges were converted from strings to numerical values, and dates were formatted for easier manipulation.\n",
    "\n",
    "3. **Feature Engineering**: New features were created to enhance the dataset. For instance, we extracted the minimum and maximum salary from the salary range column and categorized job titles into broader roles (e.g., Data Analyst, Data Scientist).\n",
    "\n",
    "4. **Text Normalization**: To facilitate analysis, we standardized text fields by converting them to lowercase and removing unnecessary whitespace or special characters, ensuring consistency across the dataset.\n",
    "\n",
    "5. **Data Transformation**: Finally, we transformed the dataset into a tidy format, organizing it for easy analysis. This included pivoting tables and encoding categorical variables as needed.\n",
    "\n",
    "By the end of Sprint 2, the dataset was well-prepared, laying a solid foundation for the exploratory data analysis in the subsequent sprint. This comprehensive data wrangling process is essential for ensuring the reliability and accuracy of our findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce35670",
   "metadata": {},
   "source": [
    "### **Changes made to the data**\n",
    "\n",
    "- Fixing the salary column .\n",
    "  1) Filling not disclosed with nan.\n",
    "  2) converting thousand to lakhs\n",
    "  3) creating 2 separate columns for staring and ending range of the salary.\n",
    "  4) Converting data type of minmum and maximum salary.\n",
    "  5) Dropping the salary column.\n",
    "- Fixing year column\n",
    "  1) Creating two columns (min_year, max_year) from the column year.\n",
    "  2) Converting the data type of the columns.\n",
    "  3) Swapppin min_YOE and max_YOE where min_YOE>max_YOE.\n",
    "- There is an empty row in the data frame which should be dropped.\n",
    "- Changing the data type of days from float to int.\n",
    "- creating a new column named job_type which will be extracted from location column.\n",
    "- Fixing location column\n",
    "  1) Removing unnecessary terms from the column.\n",
    "  2) Removed the information which is present in brackets as it is not useful.\n",
    "  3) Bangalore has multiple names like Benagluru , Bangalore Rural, replace it with a single term  i.e, Bangalore.\n",
    "  4) There are few remote jobs whose job_type is changed to Remote.\n",
    "- Creating new column named experience_level which is used to catogorize people based on year of experience.\n",
    "- Creating a new column named experience_category based on experience_level which can later be used for analysis.\n",
    "- Cleaning company column:\n",
    "    1) Stripping extra apaces.\n",
    "    2) Converting all the company names to lower case to resolve the issue of inconsistency.\n",
    "    3) Standardizing company name by replacing pepi foods with pepsico .\n",
    "- Removing duplicate columns.\n",
    "- Cleaning key_skills column.\n",
    "    1) Converting the data to lower case to maintain consistency.\n",
    "    2) The key_skills column containd abbreviations and full forms for few skills for example ml and machine learning.To maintain consistency in the data, we will replace abbreviations with their full forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469c63d",
   "metadata": {},
   "source": [
    "####  <u>**Fixing salary column**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049ec80",
   "metadata": {},
   "source": [
    "Filling not disclised values with null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed98befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['salary'] = df['salary'].replace('Not disclosed', np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4986651a",
   "metadata": {},
   "source": [
    "Removing all the text from the salary solumn so that it willl be easy to extract the minimum and maximu  salary from the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c91fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'] = df['salary'].str.replace(' Lacs PA','').str.replace(' Cr and above PA','').str.replace('5 Cr PA','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0130458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'] = df['salary'].str.replace(' PA','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e34970c",
   "metadata": {},
   "source": [
    "Converting thousands to lakhs:<br>\n",
    "Since there are only two values in thousands, we are fixing it manually, if not we can do it with loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "412abe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'] = df['salary'].str.replace('50,000','0.5').str.replace('80,000','0.8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b6d8c",
   "metadata": {},
   "source": [
    "Extracting minimum salary and maximum salary from the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4ed5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return str(''.join(re.findall('(\\d+.*)\\-',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "820c449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_salary']=df['salary'].apply(lambda x: find_min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f51d09ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>min_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10-20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1-3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.5-5.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>18-25</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5-10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2.75-5</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>22.5-25</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>35-40</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>4-8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>10-15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       salary min_salary\n",
       "33      10-20         10\n",
       "46        1-3          1\n",
       "47    4.5-5.5        4.5\n",
       "51      18-25         18\n",
       "70       5-10          5\n",
       "...       ...        ...\n",
       "2072   2.75-5       2.75\n",
       "2098  22.5-25       22.5\n",
       "2114    35-40         35\n",
       "2115      4-8          4\n",
       "2116    10-15         10\n",
       "\n",
       "[178 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['salary'].notna()][['salary','min_salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10fa3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return str(''.join(re.findall('\\-(.*)',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2676d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['max_salary'] = df['salary'].apply(lambda x: find_max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd9f126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '20', '3', '5.5', '25', '10', '22', '22.5', '9', '24', '14',\n",
       "       '15', '45', '30', '40', '2.', '17', '18', '60', '3.75', '4', '21',\n",
       "       '5', '35', '4.5', '8', '4.25', '13', '7', '65', '12', '16', '34',\n",
       "       '17.5', '', '27.5', '32.5', '42.5', '6', '4.75', '1', '11', '9.5',\n",
       "       '2.5', '70'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['max_salary'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa9500ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10-20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1-3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.5-5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>18-25</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5-10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2.75-5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>22.5-25</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>35-40</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>4-8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>10-15</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       salary min_salary max_salary\n",
       "33      10-20         10         20\n",
       "46        1-3          1          3\n",
       "47    4.5-5.5        4.5        5.5\n",
       "51      18-25         18         25\n",
       "70       5-10          5         10\n",
       "...       ...        ...        ...\n",
       "2072   2.75-5       2.75          5\n",
       "2098  22.5-25       22.5         25\n",
       "2114    35-40         35         40\n",
       "2115      4-8          4          8\n",
       "2116    10-15         10         15\n",
       "\n",
       "[178 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['salary'].notna()][['salary','min_salary','max_salary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d68ca",
   "metadata": {},
   "source": [
    "Converting the datatype of minimum salry are the maximum salry to float from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9863bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_salary'] = df['min_salary'].replace('',np.nan)\n",
    "df['max_salary'] = df['min_salary'].replace('',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74159d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '10', '1', '4.5', '18', '5', '12', '7', '14', '7.5', '30',\n",
       "       '20', '25', '8', '15', '35', '2.5', '2', '9', '11', '4', '1.5',\n",
       "       '3.5', '3', '50', '6', '0', '6.5', '9.5', '13', '27.5', '0.5',\n",
       "       '3.25', '22.5', '0.8', '5.5', '2.75', '37.5', '1.75', '60'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['min_salary'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a56a241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2172 entries, 0 to 2171\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   min_salary  176 non-null    object\n",
      " 1   max_salary  176 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df[['min_salary','max_salary']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f4c79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['min_salary','max_salary']] = df[['min_salary','max_salary']].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4841cfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2172 entries, 0 to 2171\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   min_salary  176 non-null    float64\n",
      " 1   max_salary  176 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 34.1 KB\n"
     ]
    }
   ],
   "source": [
    "df[['min_salary','max_salary']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc3618",
   "metadata": {},
   "source": [
    "Dropping salary column as it is not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9072f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('salary',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfbbd6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>years</th>\n",
       "      <th>location</th>\n",
       "      <th>days</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R&amp;D- Data Science and Analytics Lead</td>\n",
       "      <td>Pepsi Foods</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>2-5</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Machine learning,big data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Specialist- Data Science &amp; Analytics</td>\n",
       "      <td>Carrier</td>\n",
       "      <td>3.8</td>\n",
       "      <td>419.0</td>\n",
       "      <td>2-5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ai,data science,Neural networks,Artificial Int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Analytics Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>3-5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3.0</td>\n",
       "      <td>data mining,machine learning,excel,python,data...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science &amp; Analytics Engagement Lead</td>\n",
       "      <td>CANPACK</td>\n",
       "      <td>4.3</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0-15</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sql,data science,data mining,power bi,machine ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc Manager, Data Science Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3.0</td>\n",
       "      <td>excel,python,data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title      company  ratings  reviews   \n",
       "0      R&D- Data Science and Analytics Lead  Pepsi Foods      4.1   2308.0  \\\n",
       "1      Specialist- Data Science & Analytics      Carrier      3.8    419.0   \n",
       "2            Data Science Analytics Analyst    Accenture      4.0  49777.0   \n",
       "3  Data Science & Analytics Engagement Lead      CANPACK      4.3    236.0   \n",
       "4     Assoc Manager, Data Science Analytics          NaN      NaN      NaN   \n",
       "\n",
       "  years   location  days                                         key_skills   \n",
       "0  2-5   Hyderabad   2.0                          Machine learning,big data  \\\n",
       "1  2-5   Bengaluru   2.0  ai,data science,Neural networks,Artificial Int...   \n",
       "2  3-5   Bengaluru   3.0  data mining,machine learning,excel,python,data...   \n",
       "3  0-15       Pune   1.0  sql,data science,data mining,power bi,machine ...   \n",
       "4  3-6   Bengaluru   3.0                           excel,python,data mining   \n",
       "\n",
       "   min_salary  max_salary  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ecd6b7",
   "metadata": {},
   "source": [
    "####  <u>**Fixing years column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c7e5af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2-5 ', '3-5 ', '0-15', '3-6 ', '4-8 ', '9-14', '4-9 ', '8-9 ',\n",
       "       '3-8 ', '1-4 ', '4-7 ', '2-4 ', '6-11', '7-12', '0-1 ', '1-3 ',\n",
       "       '0-12', '3-7 ', '4-6 ', '8-13', '5-7 ', '5-10', '5-9 ', '6-9 ',\n",
       "       '8-10', '6-10', '6-8 ', '0-4 ', '9-12', '7-9 ', '0-11', '4-5 ',\n",
       "       '8-15', '7-10', '7-8 ', '5-12', '5-6 ', '5-8 ', '1-6 ', '2-18',\n",
       "       '2-7 ', '5-18', '2-10', '8-12', '1-5 ', '0-2 ', '2-16', '2-20',\n",
       "       '2-14', '0-20', '0-14', '6-7 ', '2-6 ', nan, '0-8 ', '2-9 ',\n",
       "       '2-3 ', '2-15', '3-9 ', '2-8 ', '5-24', '0-5 ', '5-30', '3-4 ',\n",
       "       '7-11', '0-3 ', '6-25', '6-12', '0-6 ', '5-19', '1-2 ', '4-4.',\n",
       "       '9-11', '5-20', '3-10', '0-13', '5-11', '0-18', '0-16', '2-17',\n",
       "       '5-17', '1-16', '8-11', '4-15', '8-22', '6-22', '1-10', '5-4 ',\n",
       "       '0-19', '3-15', '1-18', '4-10', '9-10', '4-18', '1-7 ', '3-20',\n",
       "       '7-15', '5-3 ', '5-25'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['years'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef1fb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_yoe(y):\n",
    "    if pd.isna(y):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b527c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_YOE'] = df['years'].apply(lambda y : find_min_yoe(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5f79de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_yoe(y):\n",
    "    if pd.isna(y):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return y[2:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55958b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['max_YOE'] = df['years'].apply(lambda y : find_max_yoe(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca973df",
   "metadata": {},
   "source": [
    "Convert the datatype of the two columns that are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e2241cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2172 entries, 0 to 2171\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   min_YOE  2168 non-null   object\n",
      " 1   max_YOE  2168 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df[['min_YOE','max_YOE']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "deb3191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['min_YOE','max_YOE']] = df[['min_YOE','max_YOE']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a72a739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2172 entries, 0 to 2171\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   min_YOE  2168 non-null   float64\n",
      " 1   max_YOE  2168 non-null   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 34.1 KB\n"
     ]
    }
   ],
   "source": [
    "df[['min_YOE','max_YOE']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e93c69",
   "metadata": {},
   "source": [
    "Swapppin min_YOE and max_YOE where min_YOE>max_YOE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75886646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This contains boolean mask of rows where df.min_YOE > df.max_YOE\n",
    "minmax=(df['min_YOE'] > df['max_YOE'])\n",
    "#swapping the values\n",
    "df.loc[minmax, ['min_YOE', 'max_YOE']] = df.loc[minmax, ['max_YOE', 'min_YOE']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735cb3d",
   "metadata": {},
   "source": [
    "Droppping year column as it is not used for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6813e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('years',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c568dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>location</th>\n",
       "      <th>days</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>min_YOE</th>\n",
       "      <th>max_YOE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R&amp;D- Data Science and Analytics Lead</td>\n",
       "      <td>Pepsi Foods</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Machine learning,big data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Specialist- Data Science &amp; Analytics</td>\n",
       "      <td>Carrier</td>\n",
       "      <td>3.8</td>\n",
       "      <td>419.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ai,data science,Neural networks,Artificial Int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Analytics Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3.0</td>\n",
       "      <td>data mining,machine learning,excel,python,data...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science &amp; Analytics Engagement Lead</td>\n",
       "      <td>CANPACK</td>\n",
       "      <td>4.3</td>\n",
       "      <td>236.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sql,data science,data mining,power bi,machine ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc Manager, Data Science Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3.0</td>\n",
       "      <td>excel,python,data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title      company  ratings  reviews   \n",
       "0      R&D- Data Science and Analytics Lead  Pepsi Foods      4.1   2308.0  \\\n",
       "1      Specialist- Data Science & Analytics      Carrier      3.8    419.0   \n",
       "2            Data Science Analytics Analyst    Accenture      4.0  49777.0   \n",
       "3  Data Science & Analytics Engagement Lead      CANPACK      4.3    236.0   \n",
       "4     Assoc Manager, Data Science Analytics          NaN      NaN      NaN   \n",
       "\n",
       "    location  days                                         key_skills   \n",
       "0  Hyderabad   2.0                          Machine learning,big data  \\\n",
       "1  Bengaluru   2.0  ai,data science,Neural networks,Artificial Int...   \n",
       "2  Bengaluru   3.0  data mining,machine learning,excel,python,data...   \n",
       "3       Pune   1.0  sql,data science,data mining,power bi,machine ...   \n",
       "4  Bengaluru   3.0                           excel,python,data mining   \n",
       "\n",
       "   min_salary  max_salary  min_YOE  max_YOE  \n",
       "0         NaN         NaN      2.0      5.0  \n",
       "1         NaN         NaN      2.0      5.0  \n",
       "2         NaN         NaN      3.0      5.0  \n",
       "3         NaN         NaN      0.0     15.0  \n",
       "4         NaN         NaN      3.0      6.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88452675",
   "metadata": {},
   "source": [
    "####  <u>**Dropping the empty row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb6897d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40428b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2171, 11)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749a9a99",
   "metadata": {},
   "source": [
    "####  <u>**Changing the data type of days from float to int.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ee4de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days'] = df['days'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d005035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 2171 entries, 0 to 2171\n",
      "Series name: days\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "2171 non-null   int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 25.4 KB\n"
     ]
    }
   ],
   "source": [
    "df['days'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d08e574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>location</th>\n",
       "      <th>days</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>min_YOE</th>\n",
       "      <th>max_YOE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R&amp;D- Data Science and Analytics Lead</td>\n",
       "      <td>Pepsi Foods</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2</td>\n",
       "      <td>Machine learning,big data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Specialist- Data Science &amp; Analytics</td>\n",
       "      <td>Carrier</td>\n",
       "      <td>3.8</td>\n",
       "      <td>419.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2</td>\n",
       "      <td>ai,data science,Neural networks,Artificial Int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Analytics Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3</td>\n",
       "      <td>data mining,machine learning,excel,python,data...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science &amp; Analytics Engagement Lead</td>\n",
       "      <td>CANPACK</td>\n",
       "      <td>4.3</td>\n",
       "      <td>236.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>sql,data science,data mining,power bi,machine ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc Manager, Data Science Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3</td>\n",
       "      <td>excel,python,data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title      company  ratings  reviews   \n",
       "0      R&D- Data Science and Analytics Lead  Pepsi Foods      4.1   2308.0  \\\n",
       "1      Specialist- Data Science & Analytics      Carrier      3.8    419.0   \n",
       "2            Data Science Analytics Analyst    Accenture      4.0  49777.0   \n",
       "3  Data Science & Analytics Engagement Lead      CANPACK      4.3    236.0   \n",
       "4     Assoc Manager, Data Science Analytics          NaN      NaN      NaN   \n",
       "\n",
       "    location  days                                         key_skills   \n",
       "0  Hyderabad     2                          Machine learning,big data  \\\n",
       "1  Bengaluru     2  ai,data science,Neural networks,Artificial Int...   \n",
       "2  Bengaluru     3  data mining,machine learning,excel,python,data...   \n",
       "3       Pune     1  sql,data science,data mining,power bi,machine ...   \n",
       "4  Bengaluru     3                           excel,python,data mining   \n",
       "\n",
       "   min_salary  max_salary  min_YOE  max_YOE  \n",
       "0         NaN         NaN      2.0      5.0  \n",
       "1         NaN         NaN      2.0      5.0  \n",
       "2         NaN         NaN      3.0      5.0  \n",
       "3         NaN         NaN      0.0     15.0  \n",
       "4         NaN         NaN      3.0      6.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaa186e",
   "metadata": {},
   "source": [
    "#### <u>**Creating job_type column from location column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc46aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_type(p):\n",
    "    if 'Hybrid' in p:\n",
    "        return 'Hybrid'\n",
    "    elif 'Remote' in p:\n",
    "        return 'Remote'\n",
    "    else:\n",
    "        return 'On Site'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e9a10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_type'] = df['location'].apply(lambda p : find_type(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67866f4e",
   "metadata": {},
   "source": [
    "#### <u>**Cleaning Location Column**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ceb285",
   "metadata": {},
   "source": [
    "Removing unnecessary terms from the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4894b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = df['location'].str.replace('Hybrid - ','')\n",
    "df['location'] = df['location'].str.replace(' / NCR','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38833ab7",
   "metadata": {},
   "source": [
    "Removed the information which is present in brackets as it is not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e1acaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(z):\n",
    "    return str(re.sub('\\(.*\\)','',z))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29f5f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] =  df['location'].apply(lambda z : remove(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4cbb785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_(l):\n",
    "    return str(re.sub('\\/.*','',l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6b092d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] =  df['location'].apply(lambda l : remove_(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846b1fb",
   "metadata": {},
   "source": [
    "Bangalore has multiple names like Benagluru , Bangalore Rural, replace it with a single term i.e, Bangalore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c74df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = df['location'].str.replace('Bengaluru','Bangalore').str.replace('Bangalore Rural, Bangalore','Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3266b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = df['location'].str.replace('Mumbai, Navi Mumbai, Mumbai','Mumbai').str.replace('Mumbai Suburban, Navi Mumbai, Mumbai ','Mumbai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fcc7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = df['location'].str.replace('Mumbai, Mumbai Suburban','Mumbai').str.replace('Mumbai, Navi Mumbai','Mumbai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97eac36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = df['location'].str.replace('Bangalore Rural','Bangalore').str.replace('Navi Mumbai','Mumbai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ddc5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = df['location'].str.replace('New Delhi, Safdarjung Enclave','Delhi').str.replace('New Delhi','Delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d47848f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = df['location'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3febb688",
   "metadata": {},
   "source": [
    "#### <u>**Creating a new column named experience_level**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ea09113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['experience_level']=df['max_YOE']-df['min_YOE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dee14b",
   "metadata": {},
   "source": [
    "#### <u>**Creating a new column named experience_category**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38bc1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category(explevel):\n",
    "    if pd.isna(explevel):\n",
    "        return np.nan\n",
    "    elif explevel == 0:\n",
    "        return 'Data Science Intern'\n",
    "    elif 0 < explevel <= 2:\n",
    "        return 'Junior Data Scientist'\n",
    "    elif 2 < explevel <= 5:\n",
    "        return 'Data Scientist (Mid Level)'\n",
    "    elif 5 < explevel <= 8:\n",
    "        return 'Senior Data Scientist'\n",
    "    elif 7 < explevel <= 10:\n",
    "        return 'Lead Data Scientist'\n",
    "    elif explevel > 10:\n",
    "        return 'Data Science Architect'\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d42ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['experience_category'] = df['experience_level'].apply(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793d0865",
   "metadata": {},
   "source": [
    "####  <u>**Fixing company column**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbbda3f",
   "metadata": {},
   "source": [
    "Stripping the spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ddcddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company'] = df['company'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346956be",
   "metadata": {},
   "source": [
    "Converting all the company names to title case to resolve the issue of inconsistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab81c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company'] = df['company'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80edd000",
   "metadata": {},
   "source": [
    "Standardizing company name by replacing pepi foods with pepsico ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63f69924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.company = df.company.replace({'pepsi foods':'pepsico'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2c067",
   "metadata": {},
   "source": [
    "#### **Removing duplicate columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6000b723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>location</th>\n",
       "      <th>days</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>min_YOE</th>\n",
       "      <th>max_YOE</th>\n",
       "      <th>job_type</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>experience_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Data Science Trainer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote</td>\n",
       "      <td>4</td>\n",
       "      <td>ai,data science,Machine learning,power bi,visu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Group Lead, Clinical Data Science</td>\n",
       "      <td>icon plc</td>\n",
       "      <td>4.1</td>\n",
       "      <td>564.0</td>\n",
       "      <td>Chennai, Bangalore, Thiruvananthapuram</td>\n",
       "      <td>8</td>\n",
       "      <td>ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Data Platform Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>5</td>\n",
       "      <td>data analytics,machine learning,statistics,pyt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Data Platform Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>data analytics,machine learning,machine learni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>agilite global solutions</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Kolkata, Mumbai, Delhi, Hyderabad, Pune, Chenn...</td>\n",
       "      <td>5</td>\n",
       "      <td>Data analysis,data science,Machine learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Data Platform Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>sas,visualization,machine learning,statistics,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>5</td>\n",
       "      <td>machine learning,deep learning,ml,python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>python,artificial intelligence,java,c++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Data Science Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>7</td>\n",
       "      <td>python,machine learning,statistics,neural netw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>artificial intelligence,deep learning,ml,ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Data Science Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Data Science Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>python,artificial intelligence,java,c++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Data Science Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>Job opening For Python Senior Developer @ Glob...</td>\n",
       "      <td>globaldata</td>\n",
       "      <td>3.6</td>\n",
       "      <td>440.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>5</td>\n",
       "      <td>NLP,Python,SQL,Machine Learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>AI/ML Scientist</td>\n",
       "      <td>verisk</td>\n",
       "      <td>3.9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2</td>\n",
       "      <td>data science,Machine learning,Statistics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>IT Infra - ML Ops</td>\n",
       "      <td>agilite global solutions</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Kolkata, Mumbai, Delhi, Hyderabad, Pune, Chenn...</td>\n",
       "      <td>3</td>\n",
       "      <td>data science,Machine learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>Job Opening For Sr Data Scientist/Lead Data Sc...</td>\n",
       "      <td>globaldata</td>\n",
       "      <td>3.6</td>\n",
       "      <td>440.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>3</td>\n",
       "      <td>Data Science,Tensorflow,Machine Learning,Deep ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>quantium analytics</td>\n",
       "      <td>3.9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>4</td>\n",
       "      <td>Data processing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Data Science Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>7</td>\n",
       "      <td>python,data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>python,machine learning,machine learning,stati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>5</td>\n",
       "      <td>python,data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>5</td>\n",
       "      <td>python,data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Data AI | Sr Data Scientist</td>\n",
       "      <td>globallogic</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4017.0</td>\n",
       "      <td>Noida</td>\n",
       "      <td>5</td>\n",
       "      <td>python,data analysis,data mining,machine learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>7</td>\n",
       "      <td>python,data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>python,machine learning,machine learning,stati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>artificial intelligence,deep learning,ml,tenso...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Data Science Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pune</td>\n",
       "      <td>8</td>\n",
       "      <td>Data analysis,data science,Machine learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>2</td>\n",
       "      <td>machine learning,machine learning,statistics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>Responsible AI Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>5</td>\n",
       "      <td>deep learning,python,c++,machine learning,neur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>Data Platform Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>3</td>\n",
       "      <td>data analytics,python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>Data Platform Engineer</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>3</td>\n",
       "      <td>data analytics,python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title   \n",
       "62                                 Data Science Trainer  \\\n",
       "259                   Group Lead, Clinical Data Science   \n",
       "406                              Data Platform Engineer   \n",
       "561                              Data Platform Engineer   \n",
       "661                                      Data Scientist   \n",
       "775                              Data Platform Engineer   \n",
       "976                                    AI / ML Engineer   \n",
       "979                                    AI / ML Engineer   \n",
       "981                                    AI / ML Engineer   \n",
       "1006                                   AI / ML Engineer   \n",
       "1013                                   AI / ML Engineer   \n",
       "1059                                   AI / ML Engineer   \n",
       "1100  Job opening For Python Senior Developer @ Glob...   \n",
       "1143                                    AI/ML Scientist   \n",
       "1164                                  IT Infra - ML Ops   \n",
       "1172  Job Opening For Sr Data Scientist/Lead Data Sc...   \n",
       "1259                                     Data Scientist   \n",
       "1303                                   AI / ML Engineer   \n",
       "1331                                   AI / ML Engineer   \n",
       "1340                                   AI / ML Engineer   \n",
       "1343                                   AI / ML Engineer   \n",
       "1454                                   AI / ML Engineer   \n",
       "1477                        Data AI | Sr Data Scientist   \n",
       "1680                                   AI / ML Engineer   \n",
       "1690                                   AI / ML Engineer   \n",
       "1711                                   AI / ML Engineer   \n",
       "1737                                     Data Scientist   \n",
       "1797                                   AI / ML Engineer   \n",
       "1800                            Responsible AI Engineer   \n",
       "2127                             Data Platform Engineer   \n",
       "2128                             Data Platform Engineer   \n",
       "\n",
       "                       company  ratings  reviews   \n",
       "62                         NaN      NaN      NaN  \\\n",
       "259                   icon plc      4.1    564.0   \n",
       "406                  accenture      4.0  49777.0   \n",
       "561                  accenture      4.0  49777.0   \n",
       "661   agilite global solutions      4.0      7.0   \n",
       "775                  accenture      4.0  49777.0   \n",
       "976                  accenture      4.0  49777.0   \n",
       "979                  accenture      4.0  49777.0   \n",
       "981                  accenture      4.0  49777.0   \n",
       "1006                 accenture      4.0  49777.0   \n",
       "1013                 accenture      4.0  49777.0   \n",
       "1059                 accenture      4.0  49777.0   \n",
       "1100                globaldata      3.6    440.0   \n",
       "1143                    verisk      3.9     41.0   \n",
       "1164  agilite global solutions      4.0      7.0   \n",
       "1172                globaldata      3.6    440.0   \n",
       "1259        quantium analytics      3.9     32.0   \n",
       "1303                 accenture      4.0  49777.0   \n",
       "1331                 accenture      4.0  49777.0   \n",
       "1340                 accenture      4.0  49777.0   \n",
       "1343                 accenture      4.0  49777.0   \n",
       "1454                 accenture      4.0  49777.0   \n",
       "1477               globallogic      3.7   4017.0   \n",
       "1680                 accenture      4.0  49777.0   \n",
       "1690                 accenture      4.0  49777.0   \n",
       "1711                 accenture      4.0  49777.0   \n",
       "1737                       NaN      NaN      NaN   \n",
       "1797                 accenture      4.0  49777.0   \n",
       "1800                 accenture      4.0  49777.0   \n",
       "2127                 accenture      4.0  49777.0   \n",
       "2128                 accenture      4.0  49777.0   \n",
       "\n",
       "                                               location  days   \n",
       "62                                               Remote     4  \\\n",
       "259              Chennai, Bangalore, Thiruvananthapuram     8   \n",
       "406                                           Hyderabad     5   \n",
       "561                                           Bangalore     3   \n",
       "661   Kolkata, Mumbai, Delhi, Hyderabad, Pune, Chenn...     5   \n",
       "775                                           Bangalore     3   \n",
       "976                                           Bangalore     5   \n",
       "979                                           Bangalore     1   \n",
       "981                                           Bangalore     7   \n",
       "1006                                          Bangalore     1   \n",
       "1013                                          Bangalore     1   \n",
       "1059                                          Bangalore     1   \n",
       "1100                                          Hyderabad     5   \n",
       "1143                                          Hyderabad     2   \n",
       "1164  Kolkata, Mumbai, Delhi, Hyderabad, Pune, Chenn...     3   \n",
       "1172                                          Hyderabad     3   \n",
       "1259                                          Hyderabad     4   \n",
       "1303                                          Bangalore     1   \n",
       "1331                                          Bangalore     7   \n",
       "1340                                          Bangalore     3   \n",
       "1343                                          Bangalore     5   \n",
       "1454                                          Bangalore     5   \n",
       "1477                                              Noida     5   \n",
       "1680                                          Bangalore     7   \n",
       "1690                                          Bangalore     3   \n",
       "1711                                          Bangalore     1   \n",
       "1737                                               Pune     8   \n",
       "1797                                          Bangalore     2   \n",
       "1800                                          Bangalore     5   \n",
       "2127                                            Chennai     3   \n",
       "2128                                            Chennai     3   \n",
       "\n",
       "                                             key_skills  min_salary   \n",
       "62    ai,data science,Machine learning,power bi,visu...         NaN  \\\n",
       "259                                                  ai         NaN   \n",
       "406   data analytics,machine learning,statistics,pyt...         NaN   \n",
       "561   data analytics,machine learning,machine learni...         NaN   \n",
       "661         Data analysis,data science,Machine learning         NaN   \n",
       "775   sas,visualization,machine learning,statistics,...         NaN   \n",
       "976            machine learning,deep learning,ml,python         NaN   \n",
       "979             python,artificial intelligence,java,c++         NaN   \n",
       "981   python,machine learning,statistics,neural netw...         NaN   \n",
       "1006        artificial intelligence,deep learning,ml,ml         NaN   \n",
       "1013                                             python         NaN   \n",
       "1059            python,artificial intelligence,java,c++         NaN   \n",
       "1100                    NLP,Python,SQL,Machine Learning         NaN   \n",
       "1143           data science,Machine learning,Statistics         NaN   \n",
       "1164                      data science,Machine learning         NaN   \n",
       "1172  Data Science,Tensorflow,Machine Learning,Deep ...         NaN   \n",
       "1259                                    Data processing         NaN   \n",
       "1303                                             python         NaN   \n",
       "1331                                 python,data mining         NaN   \n",
       "1340  python,machine learning,machine learning,stati...         NaN   \n",
       "1343                                 python,data mining         NaN   \n",
       "1454                                 python,data mining         NaN   \n",
       "1477  python,data analysis,data mining,machine learning         NaN   \n",
       "1680                                 python,data mining         NaN   \n",
       "1690  python,machine learning,machine learning,stati...         NaN   \n",
       "1711  artificial intelligence,deep learning,ml,tenso...         NaN   \n",
       "1737        Data analysis,data science,Machine learning         NaN   \n",
       "1797       machine learning,machine learning,statistics         NaN   \n",
       "1800  deep learning,python,c++,machine learning,neur...         NaN   \n",
       "2127                              data analytics,python         NaN   \n",
       "2128                              data analytics,python         NaN   \n",
       "\n",
       "      max_salary  min_YOE  max_YOE job_type  experience_level   \n",
       "62           NaN      4.0      5.0   Remote               1.0  \\\n",
       "259          NaN      8.0     13.0  On Site               5.0   \n",
       "406          NaN      5.0     10.0  On Site               5.0   \n",
       "561          NaN      3.0      5.0  On Site               2.0   \n",
       "661          NaN      5.0     10.0  On Site               5.0   \n",
       "775          NaN      3.0      8.0  On Site               5.0   \n",
       "976          NaN      5.0     10.0  On Site               5.0   \n",
       "979          NaN      2.0     15.0  On Site              13.0   \n",
       "981          NaN      7.0     12.0  On Site               5.0   \n",
       "1006         NaN      2.0     16.0  On Site              14.0   \n",
       "1013         NaN      2.0     14.0  On Site              12.0   \n",
       "1059         NaN      2.0     16.0  On Site              14.0   \n",
       "1100         NaN      5.0     10.0   Hybrid               5.0   \n",
       "1143         NaN      2.0      6.0  On Site               4.0   \n",
       "1164         NaN      3.0      8.0  On Site               5.0   \n",
       "1172         NaN      3.0      7.0   Hybrid               4.0   \n",
       "1259         NaN      4.0      8.0  On Site               4.0   \n",
       "1303         NaN      0.0     14.0  On Site              14.0   \n",
       "1331         NaN      7.0      9.0  On Site               2.0   \n",
       "1340         NaN      3.0      7.0  On Site               4.0   \n",
       "1343         NaN      5.0      7.0  On Site               2.0   \n",
       "1454         NaN      5.0      7.0  On Site               2.0   \n",
       "1477         NaN      5.0     10.0  On Site               5.0   \n",
       "1680         NaN      7.0     11.0  On Site               4.0   \n",
       "1690         NaN      3.0      5.0  On Site               2.0   \n",
       "1711         NaN      2.0     14.0  On Site              12.0   \n",
       "1737         NaN      8.0      9.0  On Site               1.0   \n",
       "1797         NaN      2.0      6.0  On Site               4.0   \n",
       "1800         NaN      5.0     10.0  On Site               5.0   \n",
       "2127         NaN      3.0      5.0  On Site               2.0   \n",
       "2128         NaN      3.0      5.0  On Site               2.0   \n",
       "\n",
       "             experience_category  \n",
       "62         Junior Data Scientist  \n",
       "259   Data Scientist (Mid Level)  \n",
       "406   Data Scientist (Mid Level)  \n",
       "561        Junior Data Scientist  \n",
       "661   Data Scientist (Mid Level)  \n",
       "775   Data Scientist (Mid Level)  \n",
       "976   Data Scientist (Mid Level)  \n",
       "979       Data Science Architect  \n",
       "981   Data Scientist (Mid Level)  \n",
       "1006      Data Science Architect  \n",
       "1013      Data Science Architect  \n",
       "1059      Data Science Architect  \n",
       "1100  Data Scientist (Mid Level)  \n",
       "1143  Data Scientist (Mid Level)  \n",
       "1164  Data Scientist (Mid Level)  \n",
       "1172  Data Scientist (Mid Level)  \n",
       "1259  Data Scientist (Mid Level)  \n",
       "1303      Data Science Architect  \n",
       "1331       Junior Data Scientist  \n",
       "1340  Data Scientist (Mid Level)  \n",
       "1343       Junior Data Scientist  \n",
       "1454       Junior Data Scientist  \n",
       "1477  Data Scientist (Mid Level)  \n",
       "1680  Data Scientist (Mid Level)  \n",
       "1690       Junior Data Scientist  \n",
       "1711      Data Science Architect  \n",
       "1737       Junior Data Scientist  \n",
       "1797  Data Scientist (Mid Level)  \n",
       "1800  Data Scientist (Mid Level)  \n",
       "2127       Junior Data Scientist  \n",
       "2128       Junior Data Scientist  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40437166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 14)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3e48812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2171, 14)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4aca6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f280f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2140, 14)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9dbf37",
   "metadata": {},
   "source": [
    "#### **Cleaning key_skills column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ccd8d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Machine learning,big data',\n",
       "       'ai,data science,Neural networks,Artificial Intelligence,Machine learning,Data processing',\n",
       "       'data mining,machine learning,excel,python,data analysis', ...,\n",
       "       'sql,azure,power bi,sql,sql',\n",
       "       'python,sql,data analytics,data analysis,sql',\n",
       "       'deep learning,python,data analysis,data science,neural networks,machine learning,artificial intelligence,sql'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['key_skills'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae9307d",
   "metadata": {},
   "source": [
    "Converting all the data to lower case to maintain consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ea1f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['key_skills'] = df['key_skills'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fde380",
   "metadata": {},
   "source": [
    "The key_skills column containd abbreviations and full forms for few skills for example ml and machine learning.To maintain consistency in the data, we will replace abbreviations with their full forms, ensuring uniformity. This will help standardize the dataset for clearer analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b9bde6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_skills={'nlp':'natural language processing','dl':'deep learning','ml':'machine learning',\n",
    "                'ai':'artificial intelligence','power bi':'powerbi','data analytics':'data analysis',\n",
    "                'statistics':'statistical analysis','gen artificial intelligence':'gen ai',\n",
    "               'statistical modelling':'statistical analysis','mysql':'sql'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3cbbba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['key_skills'] = df['key_skills'].replace(replace_skills, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4630c7",
   "metadata": {},
   "source": [
    "#  <u>**Cleaned DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "512d16e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>location</th>\n",
       "      <th>days</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>min_YOE</th>\n",
       "      <th>max_YOE</th>\n",
       "      <th>job_type</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>experience_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R&amp;D- Data Science and Analytics Lead</td>\n",
       "      <td>pepsico</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2</td>\n",
       "      <td>machine learning,big data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Specialist- Data Science &amp; Analytics</td>\n",
       "      <td>carrier</td>\n",
       "      <td>3.8</td>\n",
       "      <td>419.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>2</td>\n",
       "      <td>artificial intelligence,data science,neural ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Analytics Analyst</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>data mining,machine learning,excel,python,data...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science &amp; Analytics Engagement Lead</td>\n",
       "      <td>canpack</td>\n",
       "      <td>4.3</td>\n",
       "      <td>236.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>sql,data science,data mining,powerbi,machine l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Data Science Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc Manager, Data Science Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>excel,python,data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title    company  ratings  reviews   \n",
       "0      R&D- Data Science and Analytics Lead    pepsico      4.1   2308.0  \\\n",
       "1      Specialist- Data Science & Analytics    carrier      3.8    419.0   \n",
       "2            Data Science Analytics Analyst  accenture      4.0  49777.0   \n",
       "3  Data Science & Analytics Engagement Lead    canpack      4.3    236.0   \n",
       "4     Assoc Manager, Data Science Analytics        NaN      NaN      NaN   \n",
       "\n",
       "    location  days                                         key_skills   \n",
       "0  Hyderabad     2                          machine learning,big data  \\\n",
       "1  Bangalore     2  artificial intelligence,data science,neural ne...   \n",
       "2  Bangalore     3  data mining,machine learning,excel,python,data...   \n",
       "3       Pune     1  sql,data science,data mining,powerbi,machine l...   \n",
       "4  Bangalore     3                           excel,python,data mining   \n",
       "\n",
       "   min_salary  max_salary  min_YOE  max_YOE job_type  experience_level   \n",
       "0         NaN         NaN      2.0      5.0  On Site               3.0  \\\n",
       "1         NaN         NaN      2.0      5.0  On Site               3.0   \n",
       "2         NaN         NaN      3.0      5.0  On Site               2.0   \n",
       "3         NaN         NaN      0.0     15.0  On Site              15.0   \n",
       "4         NaN         NaN      3.0      6.0  On Site               3.0   \n",
       "\n",
       "          experience_category  \n",
       "0  Data Scientist (Mid Level)  \n",
       "1  Data Scientist (Mid Level)  \n",
       "2       Junior Data Scientist  \n",
       "3      Data Science Architect  \n",
       "4  Data Scientist (Mid Level)  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "13725157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2140 entries, 0 to 2171\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   title                2140 non-null   object \n",
      " 1   company              1682 non-null   object \n",
      " 2   ratings              1682 non-null   float64\n",
      " 3   reviews              1682 non-null   float64\n",
      " 4   location             2140 non-null   object \n",
      " 5   days                 2140 non-null   int32  \n",
      " 6   key_skills           2108 non-null   object \n",
      " 7   min_salary           176 non-null    float64\n",
      " 8   max_salary           176 non-null    float64\n",
      " 9   min_YOE              2137 non-null   float64\n",
      " 10  max_YOE              2137 non-null   float64\n",
      " 11  job_type             2140 non-null   object \n",
      " 12  experience_level     2137 non-null   float64\n",
      " 13  experience_category  2137 non-null   object \n",
      "dtypes: float64(7), int32(1), object(6)\n",
      "memory usage: 242.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79691d50",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "   \n",
    "# **Sprint 3: Exploratory Data Analysis (EDA) üîç** \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04092079",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In Sprint 3, we conducted **Exploratory Data Analysis (EDA)** to uncover patterns, trends, and insights from the cleaned job listings dataset. EDA helps in understanding the structure of the data and identifying key relationships between different variables. This process involved a combination of visual and statistical techniques.\n",
    "\n",
    "Key steps of EDA include:\n",
    "\n",
    "1. **Summary Statistics**: We calculated essential summary statistics such as mean, median, mode, and standard deviation for numeric variables like salary, experience, and job postings. These metrics helped us understand the central tendencies and spread of the data.\n",
    "\n",
    "2. **Visualizations**:\n",
    "   - **Bar Charts**: We used bar charts to compare the distribution of job titles and companies, helping us identify which roles and organizations are leading in the data science market.\n",
    "   - **Box Plots**: Box plots were employed to explore the salary range for different experience levels, revealing patterns in compensation across job roles.\n",
    "   - **Heatmaps**: Correlation heatmaps were generated to identify relationships between different features, such as salary and experience.\n",
    "\n",
    "3. **Categorical Analysis**: We analyzed categorical variables such as job titles, locations, and key skills. Grouping and visualizing these categories provided insights into the most in-demand skills and the geographic distribution of jobs.\n",
    "\n",
    "4. **Outlier Detection**: We identified outliers in salary and experience, which could indicate specialized roles or misreported data. Handling these outliers is crucial for accurate analysis in future sprints.\n",
    "\n",
    "By the end of Sprint 3, we had a comprehensive understanding of the dataset, uncovering significant trends and patterns that will guide further in-depth analysis and model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3fff2430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>location</th>\n",
       "      <th>days</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>min_YOE</th>\n",
       "      <th>max_YOE</th>\n",
       "      <th>job_type</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>experience_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R&amp;D- Data Science and Analytics Lead</td>\n",
       "      <td>pepsico</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>2</td>\n",
       "      <td>Machine learning,big data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Specialist- Data Science &amp; Analytics</td>\n",
       "      <td>carrier</td>\n",
       "      <td>3.8</td>\n",
       "      <td>419.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>2</td>\n",
       "      <td>ai,data science,Neural networks,Artificial Int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Analytics Analyst</td>\n",
       "      <td>accenture</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49777.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>data mining,machine learning,excel,python,data...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science &amp; Analytics Engagement Lead</td>\n",
       "      <td>canpack</td>\n",
       "      <td>4.3</td>\n",
       "      <td>236.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>sql,data science,data mining,power bi,machine ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Data Science Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc Manager, Data Science Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>excel,python,data mining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>On Site</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Data Scientist (Mid Level)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title    company  ratings  reviews   \n",
       "0      R&D- Data Science and Analytics Lead    pepsico      4.1   2308.0  \\\n",
       "1      Specialist- Data Science & Analytics    carrier      3.8    419.0   \n",
       "2            Data Science Analytics Analyst  accenture      4.0  49777.0   \n",
       "3  Data Science & Analytics Engagement Lead    canpack      4.3    236.0   \n",
       "4     Assoc Manager, Data Science Analytics        NaN      NaN      NaN   \n",
       "\n",
       "    location  days                                         key_skills   \n",
       "0  Hyderabad     2                          Machine learning,big data  \\\n",
       "1  Bangalore     2  ai,data science,Neural networks,Artificial Int...   \n",
       "2  Bangalore     3  data mining,machine learning,excel,python,data...   \n",
       "3       Pune     1  sql,data science,data mining,power bi,machine ...   \n",
       "4  Bangalore     3                           excel,python,data mining   \n",
       "\n",
       "   min_salary  max_salary  min_YOE  max_YOE job_type  experience_level   \n",
       "0         NaN         NaN      2.0      5.0  On Site               3.0  \\\n",
       "1         NaN         NaN      2.0      5.0  On Site               3.0   \n",
       "2         NaN         NaN      3.0      5.0  On Site               2.0   \n",
       "3         NaN         NaN      0.0     15.0  On Site              15.0   \n",
       "4         NaN         NaN      3.0      6.0  On Site               3.0   \n",
       "\n",
       "          experience_category  \n",
       "0  Data Scientist (Mid Level)  \n",
       "1  Data Scientist (Mid Level)  \n",
       "2       Junior Data Scientist  \n",
       "3      Data Science Architect  \n",
       "4  Data Scientist (Mid Level)  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc333301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
